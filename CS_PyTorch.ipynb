{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848b3aa5-2694-4899-b294-79abf493855b",
   "metadata": {},
   "source": [
    "# PyTorch Cheat Sheet\n",
    "\n",
    "<!--- Start of badges -->\n",
    "<!-- Badges: python,pytorch,machinelearning,deeplearning -->\n",
    "\n",
    "<p align=\"left\">\n",
    "<img alt=\"Deeplearning\" src=\"https://img.shields.io/badge/-Deep_Learning-333333.svg?logo=data:image/svg+xml;base64,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&style=flat-square\" />\n",
    " <img alt=\"Machinelearning\" src=\"https://img.shields.io/badge/-Machine_Learning-333333.svg?logo=data:image/svg+xml;base64,PCEtLSBMaWNlbnNlOiBBcGFjaGUuIE1hZGUgYnkgQ2FyYm9uIERlc2lnbjogaHR0cHM6Ly9naXRodWIuY29tL2NhcmJvbi1kZXNpZ24tc3lzdGVtL2NhcmJvbiAtLT4KPHN2ZyB3aWR0aD0iMzJweCIgaGVpZ2h0PSIzMnB4IiB2aWV3Qm94PSIwIDAgMzIgMzIiIGlkPSJpY29uIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxkZWZzPgogICAgPHN0eWxlPgogICAgICAuY2xzLTEgewogICAgICAgIGZpbGw6IG5vbmU7CiAgICAgIH0KICAgIDwvc3R5bGU+CiAgPC9kZWZzPgogIDxwYXRoIGZpbGw9IiNmZmZmZmYiIGQ9Ik0yNywyNGEyLjk2MDksMi45NjA5LDAsMCwwLTEuMjg1NC4zMDA4TDIxLjQxNDEsMjBIMTh2MmgyLjU4NTlsMy43MTQ2LDMuNzE0OEEyLjk2NjUsMi45NjY1LDAsMCwwLDI0LDI3YTMsMywwLDEsMCwzLTNabTAsNGExLDEsMCwxLDEsMS0xQTEuMDAwOSwxLjAwMDksMCwwLDEsMjcsMjhaIi8+CiAgPHBhdGggZmlsbD0iI2ZmZmZmZiIgZD0iTTI3LDEzYTIuOTk0OCwyLjk5NDgsMCwwLDAtMi44MTU3LDJIMTh2Mmg2LjE4NDNBMi45OTQ3LDIuOTk0NywwLDEsMCwyNywxM1ptMCw0YTEsMSwwLDEsMSwxLTFBMS4wMDA5LDEuMDAwOSwwLDAsMSwyNywxN1oiLz4KICA8cGF0aCBmaWxsPSIjZmZmZmZmIiBkPSJNMjcsMmEzLjAwMzMsMy4wMDMzLDAsMCwwLTMsMywyLjk2NTcsMi45NjU3LDAsMCwwLC4zNDgxLDEuMzczTDIwLjU5NTcsMTBIMTh2MmgzLjQwNDNsNC4zOTg5LTQuMjUyNEEyLjk5ODcsMi45OTg3LDAsMSwwLDI3LDJabTAsNGExLDEsMCwxLDEsMS0xQTEuMDAwOSwxLjAwMDksMCwwLDEsMjcsNloiLz4KICA8cGF0aCBmaWxsPSIjZmZmZmZmIiAgZD0iTTE4LDZoMlY0SDE4YTMuOTc1NiwzLjk3NTYsMCwwLDAtMywxLjM4MjNBMy45NzU2LDMuOTc1NiwwLDAsMCwxMiw0SDExYTkuMDEsOS4wMSwwLDAsMC05LDl2NmE5LjAxLDkuMDEsMCwwLDAsOSw5aDFhMy45NzU2LDMuOTc1NiwwLDAsMCwzLTEuMzgyM0EzLjk3NTYsMy45NzU2LDAsMCwwLDE4LDI4aDJWMjZIMThhMi4wMDIzLDIuMDAyMywwLDAsMS0yLTJWOEEyLjAwMjMsMi4wMDIzLDAsMCwxLDE4LDZaTTEyLDI2SDExYTcuMDA0Nyw3LjAwNDcsMCwwLDEtNi45Mi02SDZWMThINFYxNEg3YTMuMDAzMywzLjAwMzMsMCwwLDAsMy0zVjlIOHYyYTEuMDAwOSwxLjAwMDksMCwwLDEtMSwxSDQuMDhBNy4wMDQ3LDcuMDA0NywwLDAsMSwxMSw2aDFhMi4wMDIzLDIuMDAyMywwLDAsMSwyLDJ2NEgxMnYyaDJ2NEgxMmEzLjAwMzMsMy4wMDMzLDAsMCwwLTMsM3YyaDJWMjFhMS4wMDA5LDEuMDAwOSwwLDAsMSwxLTFoMnY0QTIuMDAyMywyLjAwMjMsMCwwLDEsMTIsMjZaIi8+CiAgPHJlY3QgaWQ9Il9UcmFuc3BhcmVudF9SZWN0YW5nbGVfIiBkYXRhLW5hbWU9IiZsdDtUcmFuc3BhcmVudCBSZWN0YW5nbGUmZ3Q7IiBjbGFzcz0iY2xzLTEiIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIvPgo8L3N2Zz4K&style=flat-square\" />\n",
    " <img alt=\"Python\" src=\"https://img.shields.io/badge/-Python-3776AB?logo=python&logoColor=white&style=flat-square\" />\n",
    " <img alt=\"Pytorch\" src=\"https://img.shields.io/badge/-PyTorch-EE4C2C?logo=pytorch&logoColor=white&style=flat-square\" />\n",
    "</p>\n",
    "<!--- End of badges -->\n",
    "\n",
    "<!--- Blurb\n",
    "This notebook covers fundamental PyTorch concepts and provides code examples for tensor manipulation, dataset handling, building various neural network architectures, and implementing training and testing workflows. Key topics include tensor operations, custom datasets and transforms, common layers, model creation, loss functions, and optimisers.\n",
    "-->\n",
    "\n",
    "<!--- Start of Thumbnail-->\n",
    "<!--- src=\"Images/pytorch_thumbnail.png\" --->\n",
    "<!--- End of Thumbnail-->\n",
    "\n",
    "This notebook provides a comprehensive PyTorch cheat sheet, based on material from the ['Introduction to Neural Networks and PyTorch'](https://www.coursera.org/learn/deep-neural-networks-with-pytorch/home/welcome) and ['Deep Learning with PyTorch'](https://www.coursera.org/learn/advanced-deep-learning-with-pytorch/home/welcome) course by IBM on Coursera. It covers fundamental PyTorch concepts and provides code examples for tensor manipulation, dataset handling, building various neural network architectures, and implementing training and testing workflows. Key topics include tensor operations, custom datasets and transforms, common layers, model creation, loss functions, and optimisers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e655b4-7292-4c8d-9171-c54aa49c4e65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"background-color: whitesmoke; padding: 10px; padding-left: 30px;\">\n",
       "  <h2>Table of Contents</h2>\n",
       "  <hr>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Basics\">1. Basics</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Create-tensors\">Create tensors</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Indexing\">Indexing</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Slicing\">Slicing</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Data-type-and-tensor-type\">Data type and tensor type</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Size-&-dimensions\">Size & dimensions</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Reshape\">Reshape</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Numpy-array-to/from-tensor\">Numpy array to/from tensor</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Pandas-series/dataframe-to-tensor\">Pandas series/dataframe to tensor</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Tensor-to-python-list\">Tensor to python list</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Tensor-Operations\">2. Tensor Operations</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Tensor-addition\">Tensor addition</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Tensor-multiplication\">Tensor multiplication</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Dot-product\">Dot product</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Derivatives\">Derivatives</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Partial-derivatives\">Partial derivatives</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Tensor-Functions\">3. Tensor Functions</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Mean-and-standard-deviation\">Mean and standard deviation</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Max-and-min\">Max and min</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Sin\">Sin</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Linspace\">Linspace</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Transforms\">4. Transforms</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Torchvision-transforms\">Torchvision transforms</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Create-custom-transforms-via-subclassing\">Create custom transforms via subclassing</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Compose-transforms\">Compose transforms</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Datasets\">5. Datasets</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Pre-built-datasets\">Pre-built datasets</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#MNIST\">MNIST</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Create-custom-datasets-via-subclassing\">Create custom datasets via subclassing</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Simple-dataset\">Simple dataset</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Image-dataset\">Image dataset</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Data-Loader\">6. Data Loader</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Building-blocks\">7. Building blocks</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Layers\">Layers</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Linear-layers\">Linear layers</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Convolutional-layers\">Convolutional layers</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Max-pooling-layers\">Max pooling layers</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Regularisation:-dropout-layers\">Regularisation: dropout layers</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Regularisation:-batch-normalisation\">Regularisation: batch normalisation</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Activation-functions\">Activation functions</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Weight-initialisation\">Weight initialisation</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Models\">8. Models</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Linear-Regression\">Linear Regression</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Basic-model\">Basic model</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Custom-model\">Custom model</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Logistic-Regression\">Logistic Regression</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Basic-model\">Basic model</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Custom-model\">Custom model</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Softmax\">Softmax</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Basic-model\">Basic model</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Custom-model\">Custom model</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Neural-Networks\">Neural Networks</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Conventional-Fully-Connected-Neural-Network\">Conventional Fully Connected Neural Network</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Convolutional-neural-network-(CNN)\">Convolutional neural network (CNN)</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Pre-trained-ResNet\">Pre-trained ResNet</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Train-and-Test\">9. Train and Test</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Train/test/val-split\">Train/test/val split</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Cost-function\">Cost function</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Optimiser\">Optimiser</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Learning-rate-scheduling\">Learning rate scheduling</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Define-training-procedure\">Define training procedure</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Make-predictions\">Make predictions</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Evaluate\">Evaluate</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Accuracy\">Accuracy</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Other\">10. Other</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Run-on-GPU\">Run on GPU</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Save-and-load-PyTorch-models\">Save and load PyTorch models</a></div>\n",
       "  <hr>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import generate_notebook_toc \n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "current_notebook_filename = \"CS_PyTorch.ipynb\"\n",
    "\n",
    "html_toc = generate_notebook_toc.get_html_toc(current_notebook_filename)\n",
    "\n",
    "display(Markdown(html_toc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd138d-1a31-46bd-84c7-d30410bd74a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install torch\n",
    "# !pip -q install numpy\n",
    "# !pip -q install pandas\n",
    "# !pip -q install torchvision\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb4106-638a-4ccd-91c4-5e473684427b",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db923441-39ba-4dfb-911a-90b6e60b709e",
   "metadata": {},
   "source": [
    "### Create tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7226c02-eb2e-4fa8-b376-704054ff05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1D tensor\n",
    "t = torch.tensor([0, 1, 2, 3, 4])\n",
    "t = torch.tensor([0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "t = torch.tensor([0.0, 1.0, 2.0, 3.0, 4.0], dtype=torch.int64)\n",
    "t = torch.FloatTensor([0, 1, 2, 3, 4])\n",
    "\n",
    "# Create a 2D tensor\n",
    "t = torch.tensor([[11, 12, 13], [21, 22, 23], [31, 32, 33]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc3ce4-f51f-46b5-9101-e7eb7e2a332f",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7039b4-0d3f-49be-8808-67a0a50167f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[0] # returns a tensor\n",
    "t[1, 2] # returns a tensor with the value in the 2nd row 3rd column\n",
    "t[1][2] # returns a tensor with the value in the 2nd row 3rd column\n",
    "t[0].item() # returns a number\n",
    "\n",
    "# Update value at index\n",
    "t[0] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd4458-89d8-4d70-a9f0-7792dff4b991",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84432941-b41b-4221-8910-8bbc1f4910d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[1:4] # returns new tensor containing the values in t from index 1 to index 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbedab1-5ae7-45a0-ac1d-4a050493f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor[row, col1:col2] SAME AS tensor[row][col1: col2]\n",
    "t[0, 0:2] # returns new tensor containing the values in t from row 1, columns 1 & 2\n",
    "t[0][0:2] # returns new tensor containing the values in t from row 1, columns 1 & 2\n",
    "\n",
    "# tensor[row1:row2, col] NOT THE SAME AS tensor[row1:row2][col]\n",
    "t[1:3, 1] #this is the correct way \n",
    "t[1:3][1]\n",
    "\n",
    "# Update values at slice\n",
    "t[3:5] = torch.tensor([300.0, 400.0])\n",
    "t[1:3] = 200 # Change the values on index 1 and index 2 to the same number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1327af-7056-476f-a6bc-ba3028fbd4bd",
   "metadata": {},
   "source": [
    "### Data type and tensor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467216e-0f9e-40c2-8637-3b25f0bdc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find data type\n",
    "t.dtype\n",
    "\n",
    "# Find tensor type\n",
    "t.type()\n",
    "\n",
    "# Redefine tensor type\n",
    "t = t.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7ca40-2dc0-4fb4-adb6-60617edb3e9d",
   "metadata": {},
   "source": [
    "### Size & dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a43df4-8e40-4473-8bd3-a43fe0df4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size\n",
    "t.size()\n",
    "t.shape\n",
    "\n",
    "# Dimensions\n",
    "t.ndimension()\n",
    "\n",
    "# Number of elements\n",
    "t.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27701659-c6a7-407d-8c60-b1633301f7b8",
   "metadata": {},
   "source": [
    "### Reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c44378-1280-4e62-bac9-105189615afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape tensor\n",
    "t = t.view(-1,1) # -1: infer number of rows, 1: number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff2b6e-8421-4a17-9e58-ab42fa8613b6",
   "metadata": {},
   "source": [
    "### Numpy array to/from tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbdef8e-eb2a-4720-9049-bc8e81598903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy_array = np.array([0.0, 1.0, 2.0, 3.0, 4.0]) #1D\n",
    "numpy_array = np.array([[0.0, 1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0, 9.0]]) #2D\n",
    "\n",
    "new_tensor = torch.from_numpy(numpy_array)\n",
    "back_to_numpy = new_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356c95c3-aaeb-465d-80a5-18eca1e8a3c5",
   "metadata": {},
   "source": [
    "<code>back_to_numpy</code> and <code>new_tensor</code> still point to <code>numpy_array</code>. As a result if we change <code>numpy_array</code> both <code>back_to_numpy</code> and <code>new_tensor</code> will change. For example if we set all the elements in <code>numpy_array</code> to zeros, <code>back_to_numpy</code> and <code>new_tensor</code> will follow suit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f758ccb-2bd1-4142-bf62-183e7ab0b9dd",
   "metadata": {},
   "source": [
    "### Pandas series/dataframe to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51db6a5-40fa-4ee2-9a66-fd3ed646032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D\n",
    "pandas_series=pd.Series([0.1, 2, 0.3, 10.1])\n",
    "new_tensor=torch.from_numpy(pandas_series.values)\n",
    "\n",
    "# 2D\n",
    "pandas_dataframe=pd.DataFrame({'a':[11,21,31],'b':[12,22,312]})\n",
    "new_tensor=torch.from_numpy(pandas_dataframe.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ef552-8a21-4e8c-9f6d-c3b2e73a13fe",
   "metadata": {},
   "source": [
    "### Tensor to python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ac9c8-fbec-4da1-89d3-750c5ed23cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list=t.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89afdfea-8482-4330-a8ce-b948ae43832b",
   "metadata": {},
   "source": [
    "## Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec234269-8419-4fa1-b7cc-072117abbd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tensors\n",
    "u = torch.tensor([[3, 2], [5, 1]])\n",
    "v = torch.tensor([[4, 1], [3, 6]])\n",
    "print(u)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaef36f-58cd-4ff1-b360-efa08a468243",
   "metadata": {},
   "source": [
    "### Tensor addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c8d09-20eb-438b-9005-64186f23e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor + scalar\n",
    "u+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f5e20-9bb2-4bf1-8c44-cd2f21990d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition between two tensors\n",
    "u + v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ddeb5-0e5e-4fed-91ed-89030839b7ce",
   "metadata": {},
   "source": [
    "### Tensor multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ac901-477e-4ab9-b1c5-ced7f4c75502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor * scalar\n",
    "u * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0bba0-302b-45c2-8ecc-fa2913d548a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise Product/Hadamard Product\n",
    "u * v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4501339-6e03-45dc-bcfe-0bdd20a6dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication\n",
    "torch.mm(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d245f4-fe4b-43bc-8a97-041955f41b82",
   "metadata": {},
   "source": [
    "### Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a3d66-4b44-4342-ba79-9bc00aedbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dot(u,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0182cd-7e30-4e8b-8662-9a5c4a1892f9",
   "metadata": {},
   "source": [
    "### Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff5d0a-b730-4b36-9900-66c3c6dee6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor x with the parameter 'requires_grad' set to 'True'\n",
    "x = torch.tensor(4.0, requires_grad = True)\n",
    "x = torch.linspace(-10, 10, 10, requires_grad = True)\n",
    "\n",
    "# Create a tensor y which specifies a certain function\n",
    "Y = x ** 2 + 2 * x + 1\n",
    "\n",
    "# Take the derivative\n",
    "y = torch.sum(Y) #When calculating the derivative with respect to a function with multiple values, you can use the sum trick to produce a scalar valued function and then take the gradient \n",
    "y.backward()\n",
    "\n",
    "# Now we can access the derivative at x values\n",
    "dY_dx = x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd91d7-50f2-45b0-98f6-7bdc6ae2d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data:',x.data)\n",
    "print('grad_fn:',x.grad_fn)\n",
    "print('grad:',x.grad)\n",
    "print(\"is_leaf:\",x.is_leaf)\n",
    "print(\"requires_grad:\",x.requires_grad)\n",
    "\n",
    "print('\\ndata:',y.data)\n",
    "print('grad_fn:',y.grad_fn)\n",
    "print('grad:',y.grad)\n",
    "print(\"is_leaf:\",y.is_leaf)\n",
    "print(\"requires_grad:\",y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89774a66-431a-4043-86a6-c2dab65bcd43",
   "metadata": {},
   "source": [
    "### Partial derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70b47e-19d1-4575-a7d2-adfe9efb119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors with the parameter 'requires_grad' set to 'True'\n",
    "u = torch.tensor([1.0, 2.0, 3.0],requires_grad=True)\n",
    "v = torch.tensor([2.0, 3.0, 4.0],requires_grad=True)\n",
    "\n",
    "# Create a tensor f which specifies the function\n",
    "F = u * v + u ** 2\n",
    "\n",
    "# Take the derivative\n",
    "f = torch.sum(F) #When calculating the derivative with respect to a function with multiple values, you can use the sum trick to produce a scalar valued function and then take the gradient \n",
    "f.backward()\n",
    "\n",
    "# Now we can access the derivative with respect to u and v\n",
    "dF_du = u.grad #partial derivative with respect to u\n",
    "dF_dv = v.grad #partial derivative with respect to u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2590f96-6f0c-4902-93d7-94b5ffff5108",
   "metadata": {},
   "source": [
    "## Tensor Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a8744-462f-4a06-b5c7-2f87544517fd",
   "metadata": {},
   "source": [
    "### Mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86f0d4-f84e-45c3-b645-ea964ce2c802",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.mean()\n",
    "t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d5a6b-956a-4be6-a826-789fcfd3da7c",
   "metadata": {},
   "source": [
    "### Max and min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb80bbb3-c545-400b-9662-63bfb56a42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.max()\n",
    "t.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5f18c-e25e-411a-b6a8-014d8611d9ab",
   "metadata": {},
   "source": [
    "### Sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ff1b4-eeb9-48d2-a3f6-3d6ff1012cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_tensor = torch.tensor([0, np.pi/2, np.pi])\n",
    "torch.sin(pi_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122c4bc-cd32-4b90-ae61-ae762288f3b1",
   "metadata": {},
   "source": [
    "### Linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09973979-686c-4f84-82b4-ea56dee6ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linspace(-2, 2, steps = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43e5bf-9d77-48cd-adb5-46537ee280ca",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01007af5-7a78-46d1-b9ea-81e093690d37",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Torchvision transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af398104-9e99-474c-a415-ba69a686d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.Resize((new_height, new_width)) # resize image\n",
    "transforms.CenterCrop(20) # crop image\n",
    "transforms.ToTensor() # convert image to a tensor\n",
    "transforms.RandomVerticalFlip(p=1) # vertically flip the given image randomly with a given probability (p)\n",
    "transforms.RandomHorizontalFlip(p = 1) # horizontally flip the given image randomly with a given probability (p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43deec92-7fdf-4b35-bd64-9f2e145af90e",
   "metadata": {},
   "source": [
    "### Create custom transforms via subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126afec6-201e-496b-aa65-8e4c4bfa8a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, addx = 1, muly = 2):\n",
    "        self.addx = addx\n",
    "        self.muly = muly\n",
    "    \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x + self.addx\n",
    "        y = y * self.muly\n",
    "        sample = x, y\n",
    "        return sample\n",
    "\n",
    "class mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, mult = 100):\n",
    "        self.mult = mult\n",
    "        \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x * self.mult\n",
    "        y = y * self.mult\n",
    "        sample = x, y\n",
    "        return sample\n",
    "    \n",
    "a_m = add_mult()\n",
    "\n",
    "for i in range(2):\n",
    "    x, y = dataset[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = a_m(dataset[i])\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)   \n",
    "    \n",
    "dataset_tr = custom_dataset(transform=a_m)\n",
    "print(' \\n')\n",
    "for i in range(2):\n",
    "    x, y = dataset[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = dataset_tr[i]\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10baf5-9c2a-4444-bf0f-058be34acc04",
   "metadata": {},
   "source": [
    "### Compose transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b9c4d-3ec1-4dd5-af41-481b3e795210",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "data_transform = transforms.Compose([add_mult(), mult()])\n",
    "\n",
    "x,y=dataset[0]\n",
    "x_,y_=data_transform(dataset[0])\n",
    "\n",
    "print( 'Original x: ', x, 'Original y: ', y)\n",
    "print( 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033189ee-d793-4c71-9326-b4701dd4e626",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b462d558-eaf1-49c3-90fc-4698071e540c",
   "metadata": {},
   "source": [
    "### Pre-built datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30896d9f-3d5a-4780-a2f7-8b1ff8cc6a94",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faca69be-f5ec-4ef2-b32c-d16c074c25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "validation_dataset = dsets.MNIST(root='./data', download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc34b7-ec0f-44af-8436-fdec4dfae759",
   "metadata": {},
   "source": [
    "### Create custom datasets via subclassing\n",
    "#### Simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ffb22-22e6-4f8f-b345-ff93154568bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    \n",
    "    # Constructor with defult values \n",
    "    def __init__(self, length = 100, transform = None):\n",
    "        self.len = length\n",
    "        self.x = 2 * torch.ones(length, 2)\n",
    "        self.y = torch.ones(length, 1)\n",
    "        self.transform = transform\n",
    "     \n",
    "    # Getter (called when indexing dataset, e.g. custom_dataset[0])\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)     \n",
    "        return sample\n",
    "    \n",
    "    # Get Length (executed when calling len(custom_dataset))\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "dataset = Dataset()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4c410-cda1-4aeb-996c-2ae3f79b8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing (if a transform is defined when the dataset was created, this is applied automatically)\n",
    "x,y = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7165fcc6-9bb0-4b28-b85f-0e5ceecdd971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return dataset length\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac05cc-d81d-4e17-ac54-acf9abe45b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through the dataset\n",
    "for i in range(3):\n",
    "    x, y=dataset[i]\n",
    "    print(\"index: \", i, '; x:', x, '; y:', y)\n",
    "    \n",
    "# for x,y in dataset:\n",
    "#     print(' x:', x, 'y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b25515-329a-478a-b486-427b120d5ffb",
   "metadata": {},
   "source": [
    "#### Image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee8383-f251-4fd7-9d2b-d0b0f5d3b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        \n",
    "        # Image directory\n",
    "        self.data_dir=data_dir\n",
    "        \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        data_dircsv_file=os.path.join(self.data_dir,csv_file)\n",
    "        # Load the CSV file contians image info\n",
    "        self.data_name= pd.read_csv(data_dircsv_file)\n",
    "        \n",
    "        # Number of images in dataset\n",
    "        self.len=self.data_name.shape[0] \n",
    "    \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Image file path\n",
    "        img_name=os.path.join(self.data_dir,self.data_name.iloc[idx, 1])\n",
    "        # Open image file\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        # The class label for the image\n",
    "        y = self.data_name.iloc[idx, 0]\n",
    "        \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "dataset = Dataset(csv_file=csv_file, data_dir=directory)\n",
    "image=dataset[0][0]\n",
    "y=dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a3e6c-b7ad-4c94-88df-bb39ae6e8cf0",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b1762-d149-4057-8b20-21428e2835a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create the DataLoader\n",
    "# bath size determines how many samples are used in each optimisation step\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7cae6e-016d-4b00-b8bc-aa69334c1cad",
   "metadata": {},
   "source": [
    "## Building blocks\n",
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d67ed-089c-47da-9b11-7e2798183b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da689d-cd86-419c-a579-3221c46d8e11",
   "metadata": {},
   "source": [
    "#### Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f9849-e16d-49f5-adef-d7c4e7349534",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Linear(input_size, output_size, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcdd9e9-ccd6-45d3-8254-214f65b20b65",
   "metadata": {},
   "source": [
    "#### Convolutional layers\n",
    "\n",
    "**in_channels**: a unique convolution is applied to each input channel. The result from each input channel is then added together.\n",
    "\n",
    "**out_channels:** when specifying multiple output channels, multiple convolutions with unique kernels are performed.\n",
    "\n",
    "After the convolution, the size of the image is [batch_size, out_channels, new_image_rows, new_image_columns]\n",
    "\n",
    "**stride:** number of shifts the kernel moves per iteration \n",
    "\n",
    "**padding:**\n",
    "- adds rows and columns of zeros around the image\n",
    "- can hold information about the borders\n",
    "- keeps the image at a reasonable size since it will shrink with each convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55e6b6-3d3a-4ece-9cab-2940bbd571a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride = 2, padding = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a51a4d2-3654-464d-8793-e897adc48c3e",
   "metadata": {},
   "source": [
    "#### Max pooling layers\n",
    "\n",
    "By default, stride = None, i.e. stride = kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07df038-bee9-4901-b864-a05af1d46688",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.MaxPool2d(kernel_size=2,stride=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07fb85-a8bf-40b4-a283-483185a0cd1e",
   "metadata": {},
   "source": [
    "#### Regularisation: dropout layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff8689-b09d-4ffe-96cf-ceea53193ca2",
   "metadata": {},
   "source": [
    "Dropout is a widely used regularisation technique to improve model generalisation and prevent overfitting. Overfitting occurs when a model learns the training data too well, including noise and irrelevant details. Dropout temporarily deactivates a random subset of neurons in a layer during training. The dropout rate, typically between 0.2 and 0.5, determines the proportion of neurons that are deactivated. This process forces the network to learn more robust features and reduces its reliance on specific neurons or pathways.\n",
    "\n",
    "Used for:\n",
    "\n",
    "- dense layers of fully connected networks, especially in models handling image or text data.\n",
    "- models with a large number of parameters, like deep neural networks, which are more prone to overfitting \n",
    "- when training data is scarce, dropout encourages the network to learn diverse feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364218bc-d28c-49b6-988e-7f2cae052207",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Dropout(p=dropout_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa0c78-00ae-4a24-9e84-d447dd7198d2",
   "metadata": {},
   "source": [
    "#### Regularisation: batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577ab07-95a6-4380-84e0-e309662bb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.BatchNorm1d(n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bfbf5-fd1c-4f5d-89a9-794aeb9dc2e8",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf059c00-e752-4d19-b71d-0be19eb29fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# classes which you can use when building a model with the Sequential method, or you can instantiate them to get a function object\n",
    "nn.Sigmoid()\n",
    "nn.Tanh()\n",
    "nn.ReLU()\n",
    "\n",
    "# functions\n",
    "torch.sigmoid()\n",
    "torch.tanh()\n",
    "torch.relu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccbcb6-e642-443b-9ae2-32042eef0729",
   "metadata": {},
   "source": [
    "### Weight initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc564d-6b33-45a6-b7f6-b00a6868e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Xavier initialization\n",
    "nn.init.xavier_uniform_(linear.weight) # good for tanh activation functions\n",
    "\n",
    "# He initialization\n",
    "nn.init.kaiming_uniform_(linear.weight, nonlinearity='relu') # good for relu activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb244f-68e9-4ace-8c30-4a70bf495f26",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a155f9e-4827-4641-8ed8-0ebc2ffe79f3",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d87d9-d265-4969-8dd2-e18bee1c2c0d",
   "metadata": {},
   "source": [
    "#### Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf39e4-bb9d-4c6a-bb86-b226cbf2828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "input_size=2\n",
    "output_size=1\n",
    "\n",
    "model = nn.Linear(input_size, output_size, bias=True)\n",
    "print(\"Python dictionary: \",model.state_dict()) #weights are randomly initialised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9895e7-f98c-4657-9bf5-5e98ca4ffe48",
   "metadata": {},
   "source": [
    "#### Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2431d6d3-81cd-44b6-8505-b5c766168804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class linear_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(linear_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    # Prediction function\n",
    "    def forward(self, x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat\n",
    "    \n",
    "input_size=2\n",
    "output_size=1\n",
    "model = linear_regression(input_size, output_size)\n",
    "print(\"Python dictionary: \",model.state_dict()) #weights are randomly initialised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe9d7aa-7035-4f83-a929-d80fa7c03dfd",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "#### Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a5898f-0a56-44b3-94e1-4c138008168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Sequential, Sigmoid\n",
    "\n",
    "input_size=3\n",
    "\n",
    "model = Sequential(Linear(input_size, 1), Sigmoid())\n",
    "print(\"Python dictionary: \",model.state_dict()) #weights are randomly initialised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b630474-bc96-4a60-a1d5-e9a04cd2da37",
   "metadata": {},
   "source": [
    "#### Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10948a-bbe7-474d-a8b9-9aac105b4b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class logistic_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size):\n",
    "        super(logistic_regression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        yhat = torch.sigmoid(self.linear(x))\n",
    "        return yhat\n",
    "    \n",
    "input_size=2\n",
    "model = logistic_regression(input_size)\n",
    "print(\"Python dictionary: \",model.state_dict()) #weights are randomly initialised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0384172d-3258-40f1-bd03-b0e8ffeb2a2d",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "Similar to linear regression, where the magnitude of each output determines which category a sample is assigned to. \n",
    "with multiple outputs (i.e. for non-binary classification).\n",
    "\n",
    "#### Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2efaba-c558-4ae2-8008-b2d12d542b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Sequential\n",
    "\n",
    "input_size=1\n",
    "output_size=3\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5af50-abb4-4b51-9536-bbd6198572ac",
   "metadata": {},
   "source": [
    "#### Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b7d11e-2dba-46a7-8500-648bb169fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SoftMax(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SoftMax, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        z = self.linear(x)\n",
    "        return z\n",
    "\n",
    "input_size = 5\n",
    "num_classes = 10\n",
    "model = SoftMax(input_size, num_classes)\n",
    "print(\"Python dictionary: \",model.state_dict()) #weights are randomly initialised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d9d960-747e-4b4d-9c4a-eb32bb34473c",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a84b2-4487-4b7c-a762-70a9e2a5620f",
   "metadata": {},
   "source": [
    "#### Conventional Fully Connected Neural Network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce5937-ade9-4703-b83a-b84b3f290227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "hidden_neurons = 9\n",
    "\n",
    "model= torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_size, hidden_neurons), \n",
    "    torch.nn.Sigmoid(), #OR: torch.nn.Tanh(), torch.nn.ReLU()\n",
    "    torch.nn.Linear(hidden_neurons,output_size),\n",
    "    \n",
    "    # For binary classification: \n",
    "    torch.nn.Sigmoid() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc130ab-9967-40d4-a07f-3cc9b5481eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, Layers,p=0):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #Optional: drop out (no drop out if p=0)\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "        \n",
    "        self.hidden = nn.ModuleList()\n",
    "        self.batchnorm = nn.ModuleList()\n",
    "        \n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            linear = nn.Linear(input_size, output_size)\n",
    "            self.hidden.append(linear)\n",
    "            \n",
    "            #Optional: custom weight initialisation\n",
    "            nn.init.xavier_uniform_(linear.weight) # good for tanh activation\n",
    "            nn.init.kaiming_uniform_(linear.weight, nonlinearity='relu') # good for relu activation\n",
    "            \n",
    "            #Optional: batch normalisation\n",
    "            bn = nn.BatchNorm1d(output_size)\n",
    "            self.batchnorm.append(bn)\n",
    "             \n",
    "    # Prediction\n",
    "    def forward(self, activation):\n",
    "        L = len(self.hidden)\n",
    "        for (l, linear_transform, batch_norm) in zip(range(L), self.hidden):\n",
    "            \n",
    "            if l < L - 1: # Hidden layer activation function\n",
    "                activation = torch.relu(self.drop(linear_transform(activation)))\n",
    "                # activation = torch.tanh(self.drop(linear_transform(activation)))\n",
    "                # activation = torch.sigmoid(self.drop(linear_transform(activation)))\n",
    "                \n",
    "                # if using batch normalisation:\n",
    "                activation = batch_norm(activation)\n",
    "        \n",
    "            else: # Output layer activation function\n",
    "                \n",
    "                # For binary classification:\n",
    "                activation = torch.sigmoid(linear_transform(activation)) #sigmoid function applied to output layer to get binary probabilities\n",
    "                \n",
    "                # For regression / multi-class classification: \n",
    "                activation = linear_transform(activation)\n",
    "                \n",
    "        return activation\n",
    "\n",
    "Layers = [2, 50, 3] # first element: size of the input layer, last element: size of output layer, central elements: number of neurons in hidden layers\n",
    "model = Net(Layers, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b1d1c-a611-4dd9-bf46-6ddd042bbb64",
   "metadata": {},
   "source": [
    "#### Convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c7005-a4d6-4a9a-bd5e-e21d8ca5cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    # Contructor\n",
    "    def __init__(self, out_1=16, out_2=32):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        #first Convolutional layers \n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
    "        #batch normalisation \n",
    "        self.conv1_bn = nn.BatchNorm2d(out_1)\n",
    "        #max pooling \n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "        #second Convolutional layers\n",
    "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, stride=1, padding=2)\n",
    "        #batch normalisation \n",
    "        self.conv2_bn = nn.BatchNorm2d(out_2)\n",
    "        #max pooling \n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        #fully connected layer \n",
    "        self.fc1 = nn.Linear(out_2 * 4 * 4, 10)\n",
    "        #batch normalisation \n",
    "        self.bn_fc1 = nn.BatchNorm1d(10)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x=self.conv1_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x=self.conv2_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x=self.bn_fc1(x)\n",
    "        return x\n",
    "\n",
    "out_1 = 16\n",
    "out_2 = 32\n",
    "\n",
    "model = CNN(out_1, out_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9f2c7-a0fa-4192-b591-c13073f96f2b",
   "metadata": {},
   "source": [
    "### Pre-trained ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380aaf5-28d3-404b-a786-6bbd62d5654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import optim\n",
    "\n",
    "model = models.resnet18(pretrained = True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.fc = nn.Linear(512,7)\n",
    "\n",
    "# specify that the optimizer should only use parameters where the grad attribute is true \n",
    "optimizer = optim.Adam([parameters for parameters in model.parameters() if parameters.requires_grad], lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df86e8dd-d027-4580-8ff8-0b4bf6f7de07",
   "metadata": {},
   "source": [
    "## Train and Test\n",
    "\n",
    "### Train/test/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1533ca-ab44-4f99-a86c-d800e8d7c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of samples to be used for training and validation (5% for validation).\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "\n",
    "# Randomly split the training dataset into training and validation datasets using `random_split`.\n",
    "# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59404edb-5516-4353-8462-a3b432c75aca",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4730f6-1ccc-47c0-b608-beb2785cccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Mean-sqaured error\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Binary cross entropy loss (good for classification)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Cross entropy loss (good for multi-class classification)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437d88f-5f7b-471c-9a06-58d42e9d59c0",
   "metadata": {},
   "source": [
    "### Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e81af9-8ae7-4c27-9f06-3c34930b746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.1) # with momentum you can avoid getting stuck at saddle points or local minima\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aaf985-7564-4c02-a6c1-7e54b2e60899",
   "metadata": {},
   "source": [
    "### Learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f70f2b-34ab-4f93-83d3-add2e0aa7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusts the learning rate during training, reducing it by a factor (gamma) after every epoch (step) to improve convergence and fine-tune the model's performance.\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee53d1-8ae9-4d3f-a0ad-9be7f186cbbc",
   "metadata": {},
   "source": [
    "### Define training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55007e9e-cc03-47dd-8975-6b8bbae3a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    \n",
    "    cost_list=[]\n",
    "    accuracy_list=[]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        COST=0\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            COST+=loss.data\n",
    "        cost_list.append(COST)\n",
    "        \n",
    "        correct = 0\n",
    "        model.eval()\n",
    "        for x, y in validation_loader:\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            _, label = torch.max(z, 1)\n",
    "            correct += (label == y).sum().item()\n",
    "    \n",
    "        accuracy = 100 * (correct / len(validation_dataset))\n",
    "        accuracy_list.append(accuracy)\n",
    "    \n",
    "    return cost_list, accuracy_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb80fad8-8001-4191-ab3d-1f50f7bc344a",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256cb06c-3891-4839-88a6-41dbb6990431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Softmax\n",
    "\n",
    "# Regression\n",
    "yhat = model(x)\n",
    "\n",
    "# Binary classification\n",
    "z =  model(data_set.x)\n",
    "yhat = (z[:,0] > 0.5)\n",
    "\n",
    "# Multi-class classification\n",
    "Softmax_fn = Softmax(dim=-1)\n",
    "z =  model(data_set.x)\n",
    "probability = Softmax_fn(z)\n",
    "_, yhat = z.max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b43b47-ad5e-4b24-b262-ac94cb04df7a",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fb434-69a9-46cf-9e49-85378532e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification\n",
    "accuracy = (data_set.y == yhat).mean()\n",
    "\n",
    "# Multi-class classification\n",
    "correct = (data_set.y == yhat).sum().item()\n",
    "accuracy = correct / len(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55646b69-df14-46b8-8db0-7b720338ad47",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d9f461-bd16-4e00-bf71-efac8b9009c0",
   "metadata": {},
   "source": [
    "### Run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d0f50-56bc-407c-8e76-fb0cc73adf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9fcf34-b823-49a9-a2b9-050de363b57c",
   "metadata": {},
   "source": [
    "### Save and load PyTorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef7cd8-2864-4f37-9df8-0b738449a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'my_model.pth')\n",
    "model.load_state_dict(torch.load('my_model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-lab-kernel",
   "language": "python",
   "name": "jupyter-lab-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
