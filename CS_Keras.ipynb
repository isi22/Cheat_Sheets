{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a34b703-83bc-481d-94fc-f4fedfb04dbf",
   "metadata": {},
   "source": [
    "# Keras Cheat Sheet\n",
    "\n",
    "<!--- Start of badges -->\n",
    "<!-- Badges: python,keras,machinelearning,deeplearning -->\n",
    "\n",
    "<p align=\"left\">\n",
    "<img alt=\"Deeplearning\" src=\"https://img.shields.io/badge/-Deep_Learning-333333.svg?logo=data:image/svg+xml;base64,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&style=flat-square\" />\n",
    " <img alt=\"Keras\" src=\"https://img.shields.io/badge/-Keras-D00000?logo=keras&logoColor=white&style=flat-square\" />\n",
    " <img alt=\"Machinelearning\" src=\"https://img.shields.io/badge/-Machine_Learning-333333.svg?logo=data:image/svg+xml;base64,PCEtLSBMaWNlbnNlOiBBcGFjaGUuIE1hZGUgYnkgQ2FyYm9uIERlc2lnbjogaHR0cHM6Ly9naXRodWIuY29tL2NhcmJvbi1kZXNpZ24tc3lzdGVtL2NhcmJvbiAtLT4KPHN2ZyB3aWR0aD0iMzJweCIgaGVpZ2h0PSIzMnB4IiB2aWV3Qm94PSIwIDAgMzIgMzIiIGlkPSJpY29uIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxkZWZzPgogICAgPHN0eWxlPgogICAgICAuY2xzLTEgewogICAgICAgIGZpbGw6IG5vbmU7CiAgICAgIH0KICAgIDwvc3R5bGU+CiAgPC9kZWZzPgogIDxwYXRoIGZpbGw9IiNmZmZmZmYiIGQ9Ik0yNywyNGEyLjk2MDksMi45NjA5LDAsMCwwLTEuMjg1NC4zMDA4TDIxLjQxNDEsMjBIMTh2MmgyLjU4NTlsMy43MTQ2LDMuNzE0OEEyLjk2NjUsMi45NjY1LDAsMCwwLDI0LDI3YTMsMywwLDEsMCwzLTNabTAsNGExLDEsMCwxLDEsMS0xQTEuMDAwOSwxLjAwMDksMCwwLDEsMjcsMjhaIi8+CiAgPHBhdGggZmlsbD0iI2ZmZmZmZiIgZD0iTTI3LDEzYTIuOTk0OCwyLjk5NDgsMCwwLDAtMi44MTU3LDJIMTh2Mmg2LjE4NDNBMi45OTQ3LDIuOTk0NywwLDEsMCwyNywxM1ptMCw0YTEsMSwwLDEsMSwxLTFBMS4wMDA5LDEuMDAwOSwwLDAsMSwyNywxN1oiLz4KICA8cGF0aCBmaWxsPSIjZmZmZmZmIiBkPSJNMjcsMmEzLjAwMzMsMy4wMDMzLDAsMCwwLTMsMywyLjk2NTcsMi45NjU3LDAsMCwwLC4zNDgxLDEuMzczTDIwLjU5NTcsMTBIMTh2MmgzLjQwNDNsNC4zOTg5LTQuMjUyNEEyLjk5ODcsMi45OTg3LDAsMSwwLDI3LDJabTAsNGExLDEsMCwxLDEsMS0xQTEuMDAwOSwxLjAwMDksMCwwLDEsMjcsNloiLz4KICA8cGF0aCBmaWxsPSIjZmZmZmZmIiAgZD0iTTE4LDZoMlY0SDE4YTMuOTc1NiwzLjk3NTYsMCwwLDAtMywxLjM4MjNBMy45NzU2LDMuOTc1NiwwLDAsMCwxMiw0SDExYTkuMDEsOS4wMSwwLDAsMC05LDl2NmE5LjAxLDkuMDEsMCwwLDAsOSw5aDFhMy45NzU2LDMuOTc1NiwwLDAsMCwzLTEuMzgyM0EzLjk3NTYsMy45NzU2LDAsMCwwLDE4LDI4aDJWMjZIMThhMi4wMDIzLDIuMDAyMywwLDAsMS0yLTJWOEEyLjAwMjMsMi4wMDIzLDAsMCwxLDE4LDZaTTEyLDI2SDExYTcuMDA0Nyw3LjAwNDcsMCwwLDEtNi45Mi02SDZWMThINFYxNEg3YTMuMDAzMywzLjAwMzMsMCwwLDAsMy0zVjlIOHYyYTEuMDAwOSwxLjAwMDksMCwwLDEtMSwxSDQuMDhBNy4wMDQ3LDcuMDA0NywwLDAsMSwxMSw2aDFhMi4wMDIzLDIuMDAyMywwLDAsMSwyLDJ2NEgxMnYyaDJ2NEgxMmEzLjAwMzMsMy4wMDMzLDAsMCwwLTMsM3YyaDJWMjFhMS4wMDA5LDEuMDAwOSwwLDAsMSwxLTFoMnY0QTIuMDAyMywyLjAwMjMsMCwwLDEsMTIsMjZaIi8+CiAgPHJlY3QgaWQ9Il9UcmFuc3BhcmVudF9SZWN0YW5nbGVfIiBkYXRhLW5hbWU9IiZsdDtUcmFuc3BhcmVudCBSZWN0YW5nbGUmZ3Q7IiBjbGFzcz0iY2xzLTEiIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIvPgo8L3N2Zz4K&style=flat-square\" />\n",
    " <img alt=\"Python\" src=\"https://img.shields.io/badge/-Python-3776AB?logo=python&logoColor=white&style=flat-square\" />\n",
    "</p>\n",
    "<!--- End of badges -->\n",
    "\n",
    "<!--- Blurb\n",
    "This notebook is a hands-on toolkit for Keras, covering the complete workflow for building neural networks, from data preparation to model evaluation. It provides clear examples for using both the Sequential and Functional APIs to build a range of architectures, including basic neural networks to advanced CNNs for image classification and RNNs for time series forecasting.\n",
    "-->\n",
    "\n",
    "<!--- Start of Thumbnail-->\n",
    "<!--- src=\"Images/keras_thumbnail.png\" --->\n",
    "<!--- End of Thumbnail-->\n",
    "\n",
    "This notebook provides a comprehensive Keras cheat sheet, based on material from the ['Deep Learning with Keras and TensorFlow'](https://www.coursera.org/learn/building-deep-learning-models-with-tensorflow/home/welcome) course by IBM on Coursera. It covers essential concepts and code examples for building and training neural networks, including layers, models, pre-processing, training/testing, and other Keras features.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82552bb5-9ee3-4c15-8e1c-1460386f6559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"background-color: whitesmoke; padding: 10px; padding-left: 30px;\">\n",
       "  <h2>Table of Contents</h2>\n",
       "  <hr>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Layers\">1. Layers</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Custom-Layers-(Subclassing)\">Custom Layers (Subclassing)</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Input\">Input</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Dense\">Dense</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Convolution\">Convolution</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Transpose-Convolution\">Transpose Convolution</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Dropout\">Dropout</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Batch-Normalization\">Batch Normalization</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Models\">2. Models</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Custom-Models-(Subclassing)\">Custom Models (Subclassing)</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Conventional-Fully-Connected-Neural-Network\">Conventional Fully Connected Neural Network</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Regression\">Regression</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Classification\">Classification</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Convolutional-Neural-Network-(CNN)\">Convolutional Neural Network (CNN)</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Simple-CNN\">Simple CNN</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#VGG\">VGG</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#ResNet\">ResNet</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Pre-trained:-VGG16\">Pre-trained: VGG16</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Recurrent-Neural-Network-(RNN)\">Recurrent Neural Network (RNN)</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Simple-RNN\">Simple RNN</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Long-Short-Term-Memory-(LSTM)\">Long Short-Term Memory (LSTM)</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Transformers\">Transformers</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Prediction:-sequential-data-tasks\">Prediction: sequential data tasks</a></div>\n",
       "  <div style=\"padding-left: 50px;\"><a href=\"#Text-Generation\">Text Generation</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Q-learning-(Reinforcement-Learning)\">Q-learning (Reinforcement Learning)</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Autoencoders\">Autoencoders</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Diffusion-models\">Diffusion models</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Generative-Adversarial-Networks-(GANs)\">Generative Adversarial Networks (GANs)</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Pre-processing\">3. Pre-processing</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Data-Augmentation\">Data Augmentation</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Train-and-Test\">4. Train and Test</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Build-model\">Build model</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Compile\">Compile</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Fit\">Fit</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Evaluate\">Evaluate</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Hyperparameter-Tuning\">Hyperparameter Tuning</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Learning-rate-scheduling\">Learning rate scheduling</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Custom-training-loops\">Custom training loops</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Custom-callbacks\">Custom callbacks</a></div>\n",
       "  <div style=\"font-weight: bold; font-size: 1.1em;\"><a href=\"#Other-Features\">5. Other Features</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Save-and-load-Keras-models\">Save and load Keras models</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Mixed-precision-training\">Mixed precision training</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Model-pruning\">Model pruning</a></div>\n",
       "  <div style=\"padding-left: 25px;\"><a href=\"#Quantization\">Quantization</a></div>\n",
       "  <hr>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import generate_notebook_toc \n",
    "from IPython.display import display, Markdown\n",
    "current_notebook_filename = \"CS_Keras.ipynb\"\n",
    "display(Markdown(generate_notebook_toc.get_html_toc(current_notebook_filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6405660-6c05-44fb-b30f-5f9abd23cac8",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6905e-00ec-4bf6-b361-8cffaf460b4e",
   "metadata": {},
   "source": [
    "### Custom Layers (Subclassing)\n",
    "- Allows you to define your own operations in a neural network\n",
    "- Allows implementation of custom functionality not provided by existing Keras layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61637e6b-d39b-4d80-a102-a01e5c578812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras.models import Sequential\n",
    "\n",
    "class CustomLayer(Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.relu(tf.matmul(inputs, self.w) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959ab87-464f-483f-9a6b-6a066a5d2d5e",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86eb2a-4298-4820-82ca-3ca3249de871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "input_layer = Input(shape=(28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c37cfef-6e5a-4939-8cc2-8fa93d03c0c4",
   "metadata": {},
   "source": [
    "### Dense\n",
    "- Fully-connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e5dee-b897-4dd4-925e-5be373761860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.initializers import HeNormal\n",
    "\n",
    "dense_layer = Dense(units=100, activation='relu')\n",
    "\n",
    "# To implement He weight initialization (set the initial weights to avoid issues like vanishing or exploding gradients)\n",
    "# He initialization is suitable for layers with relu activation, helping maintain a stable gradient flow during training.\n",
    "dense_layer = Dense(units=100, activation='relu', kernel_initializer=HeNormal())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1716de8f-5bef-4662-94c0-54f2feb61787",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "- A filter/kernel is moved across the input image to produce a feature map. \n",
    "- Reduces the spatial dimensions of the input, which is useful for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be70dc3-1b69-41b2-b81f-7ae3598dd7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "conv_layer = Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22a638-5153-4e9e-be04-1f7339d966b1",
   "metadata": {},
   "source": [
    "### Transpose Convolution\n",
    "- Zeroes are inserted between the elements of the input feature map before applying the convolution operation\n",
    "- Performs the inverse convolution operation, effectively up-sampling the input image to a larger higher resolution size\n",
    "**Applications:** image generation (in generative adversarial networks, i.e. GANs), super-resolution, semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc516cd-5946-423e-ba94-6fb4d905648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2DTranspose\n",
    "transpose_conv_layer = Conv2DTranspose(filters=1, kernel_size=(3, 3), activation='sigmoid', padding='same') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c393a-d5a1-49e4-a37c-22f77bf90747",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "- A regularisation technique that helps prevent overfitting in neural networks. \n",
    "- Some of the input units are randomly set to zero at each update cycle. This prevents the model from becoming overly reliant on any specific neurons, which encourages the network to learn more robust features that generalize better to unseen data.\n",
    "- Dropout is only applied during training, not during inference.\n",
    "- The dropout rate is a hyperparameter that determines the fraction of neurons to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab0318-d0c3-47e7-87ab-950fe64a1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "dropout_layer = Dropout(rate=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c7ec5-a282-4fc8-971b-e75c6bae0fd3",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20f6402-0b55-4382-8ad7-157de23c3f80",
   "metadata": {},
   "source": [
    "- A regularisation technique used to improve the training stability and speed of neural networks. \n",
    "- The output of a previous layer is normalised by re-centering (mean of zero) and re-scaling (variance of one) the data, which helps in stabilising the learning process. By reducing the internal covariate shift (the changes in the distribution of layer inputs), batch normalisation allows the model to use higher learning rates, which often speeds up convergence.\n",
    "- It is applied during both training and inference, although its behaviour varies slightly between the two phases.\n",
    "- Introduces two learnable parameters that allow the model to scale and shift the normalised output, which helps in restoring the model's representational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a48e97-d2db-4996-b067-582dea5a7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "batch_norm_layer = BatchNormalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192e1ec-ebfe-4566-84ab-b13bc878189b",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca11f4e8-71f4-4125-828c-eb7b04f40c01",
   "metadata": {},
   "source": [
    "### Custom Models (Subclassing)\n",
    "- Allows you to define custom and dynamic models\n",
    "- Particularly useful when the forward pass cannot be defined statically\n",
    "- Widely used for custom training loops and non-standard architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad01d0-2157-468a-9e32-a63e9faeb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "\n",
    "class CustomModel(Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        #Define layers\n",
    "        self.dense1 = Dense(64, activation='relu')\n",
    "        self.dense2 = Dense(10, activation='softmax')\n",
    "    def call(self, inputs):\n",
    "        # Forward pass\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)\n",
    "    \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559fe3e-7e4e-4a93-84ac-3f8f49c5b0a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conventional Fully Connected Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16bf75-97de-415a-ae62-521dc5b0f090",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d7528-3c12-4e8f-b6b3-2a4b5f439b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "def regression_NN(input_shape, output_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_shape,)))\n",
    "    model.add(Dense(units=50, activation='relu'))\n",
    "    model.add(Dense(units=50, activation='relu'))\n",
    "    model.add(Dense(units=output_shape))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8116e-1a26-46b1-b18f-17c5ac77d64c",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed9d27-4b38-4893-8231-e39aba4dd457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "def classification_NN(input_shape, output_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_shape,)))\n",
    "    model.add(Dense(units=50, activation='relu'))\n",
    "    model.add(Dense(units=50, activation='relu'))\n",
    "    model.add(Dense(units=output_shape, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047dd1f-b14a-4ade-aeb4-8e35814f63ab",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network (CNN)\n",
    "\n",
    "**Applications:** image recognition, object detection, computer vision\n",
    "\n",
    "**Features:**\n",
    "- Convolutional layers: extract features from the input image\n",
    "- Pooling layers: downsample the feature maps to reduce dimensionality\n",
    "- Fully connected layers: perform final classification\n",
    "\n",
    "**Advanced CNN architectures:** VGG, ResNet, inception networks, deeper networks\n",
    "\n",
    "#### Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d279d78-332e-4dce-9ad5-fa7fa87c0793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "def simple_CNN(input_shape,output_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    model.add(Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    # Optional: repeat convolutional and pooling layers\n",
    "    model.add(Conv2D(filters=8, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=output_shape, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630fb10f-f9c9-4a50-86cd-29c060e827bc",
   "metadata": {},
   "source": [
    "#### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172082a-f132-494d-84c9-9bf9a5480f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "def VGG_CNN(input_shape,output_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dense(units=output_shape, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef430b8-291c-4869-a82e-f8cc9e1b18ce",
   "metadata": {},
   "source": [
    "#### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83dc037-3099-4c2c-a9b0-74c0ac86da88",
   "metadata": {},
   "source": [
    "- Introduces residual connections, which help train deep networks by addressing the vanishing gradient problem. \n",
    "- Residual connections allow the network to learn identity mappings, making it easier to train deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6abfd3-9328-47e5-8f41-233547c4c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Add, Activation\n",
    "\n",
    "def ResNet_CNN(input_shape,output_shape):\n",
    "    \n",
    "    def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "        shortcut = x\n",
    "        x = Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "    x = Flatten()(x)\n",
    "    output_layer = Dense(output_shape, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffdcd57-acd9-4463-927c-8cf77f9891d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Pre-trained: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e1943-b476-4a96-b08d-95fe974928f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "def VGG16_CNN(input_shape, output_shape):\n",
    "    \n",
    "    # Load the VGG16 model pre-trained on ImageNet\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freeze the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "    model.add(Dense(units=output_shape, activation='sigmoid'))\n",
    "    \n",
    "    #Optional: fine-tuning \n",
    "    for layer in base_model.layers[-4:]: #Unfreeze the last four layers of the VGG16 model\n",
    "        layer.trainable = True \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b1f5a-11f4-4cbc-bdf1-e8d2ca16cb67",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network (RNN)\n",
    "- Take in the output from previous data points\n",
    "- Very good at modeling patterns and sequences of data\n",
    "\n",
    "**Applications:** image generation, handwriting generation, auto-captioning, genomes, stock markets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4098e7fc-415f-43d7-9ec5-ce1a0ff4f770",
   "metadata": {},
   "source": [
    "#### Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413150c6-d27a-4105-9390-339cbfc1a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, SimpleRNN\n",
    "\n",
    "def simple_RNN(input_shape,output_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    model.add(SimpleRNN(units=50, activation='relu'))\n",
    "    model.add(Dense(units=output_shape))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc32d0-f0ac-4ba3-97cd-6cba2751906d",
   "metadata": {},
   "source": [
    "#### Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa5f0a-c283-4269-9e56-4abe725d0e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, LSTM\n",
    "\n",
    "def LSTM_RNN(input_shape,output_shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    model.add(LSTM(units=50, activation='relu'))\n",
    "    model.add(Dense(units=output_shape))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20edba46-09d2-4b35-8052-0eda6c63ac24",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transformers\n",
    "- Leverage self attention mechanisms to process input data in parallel\n",
    "- Consist of two main parts, the encoder and the decoder with:\n",
    "  - Self attention mechanism layers: captures dependencies that are far apart in the input sequence\n",
    "  - Feed forward neural network layers: transforms input data\n",
    "- Like RNNs and LSTMs, good for sequential data (e.g. natural language text and time series data), with the additional advantage of being better at handling longer sequencies and parallerisation\n",
    "- The key components of the transformer model include an embedding layer, multiple transformer blocks, and a final dense layer for output prediction\n",
    "\n",
    "**Examples:** BERT, GPT, image transformers\n",
    "\n",
    "**Applications:** Natural Language Processing (NLP) (e.g. machine translation, question answering, text summarisation, text-to-image), time-series forecasting, computer vision, speech recognition, reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252e9fb-242f-4d60-af22-924266babb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Dense, LayerNormalization, Dropout, Input, Flatten, MultiHeadAttention, Embedding\n",
    "from keras.models import Sequential, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "#Define the Multi-Head Self-Attention mechanism\n",
    "class MultiHeadSelfAttention(Layer):\n",
    "#implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): #computes the attention scores and weighted sum of the values \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): #splits the input into multiple heads for parallel attention computation\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): #applies the self-attention mechanism and combines the heads\n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "#Define the Transformer block\n",
    "class TransformerBlock(Layer): \n",
    "#combines multi-head self-attention with a feed-forward neural network and normalization layers\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        \n",
    "        #EITHER:\n",
    "        # self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        #OR:\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        \n",
    "        self.ffn = Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) #dropout used to prevent overfitting\n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): #applies the self-attention, followed by the feedforward network with residual connections and layer normalization\n",
    "        # EITHER:\n",
    "        # attn_output = self.att(inputs) \n",
    "        # OR:\n",
    "        attn_output = self.att(inputs, inputs)    \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29de2ee7-1e2b-48b7-8d5d-8803c8621310",
   "metadata": {},
   "source": [
    "#### Prediction: sequential data tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bb904-b342-48ce-908d-d239c64c1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Transformer Encoder\n",
    "class TransformerEncoder(Layer):\n",
    "#composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture.\n",
    "\n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x  \n",
    "\n",
    "def Predictions_Transformer(input_shape, output_shape):\n",
    "#defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output\n",
    "\n",
    "    # Hyperparameters\n",
    "    embed_dim = 128 \n",
    "    num_heads = 8 \n",
    "    ff_dim = 512 \n",
    "    num_layers = 4 \n",
    "\n",
    "    # Define the Transformer Encoder \n",
    "    transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "    input_layer = Input(shape=input_shape) \n",
    "\n",
    "    # Project the inputs to the embed_dim \n",
    "    x = Dense(units=embed_dim)(input_layer) #embedding layer\n",
    "    encoder_outputs = transformer_encoder(x) \n",
    "    flatten = Flatten()(encoder_outputs) \n",
    "    output_layer = Dense(units=output_shape)(flatten) \n",
    "    model = Model(input_layer, output_layer) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6332a8-7c44-4b1b-939c-c4109f2e9cc5",
   "metadata": {},
   "source": [
    "#### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e62bc-1557-4ab2-9a36-887c231e31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "class TextGen_TransformerModel(Model):  # Model is now properly imported\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers, seq_length):\n",
    "        super(TextGen_TransformerModel, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embed_dim)\n",
    "        self.pos_encoding = self.positional_encoding(seq_length, embed_dim)\n",
    "        self.transformer_blocks = [TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_layers)]\n",
    "        self.dense = Dense(vocab_size)\n",
    "\n",
    "    def positional_encoding(self, seq_length, embed_dim):\n",
    "        angle_rads = self.get_angles(np.arange(seq_length)[:, np.newaxis], np.arange(embed_dim)[np.newaxis, :], embed_dim)\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def get_angles(self, pos, i, embed_dim):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(embed_dim))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        x = self.embedding(inputs)\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x, training=training)  # Pass training argument correctly\n",
    "        output = self.dense(x)\n",
    "        return output\n",
    "    \n",
    "def TextGen_Transformer():\n",
    "\n",
    "    # Hyperparameters \n",
    "    embed_dim = 256 \n",
    "    num_heads = 4 \n",
    "    ff_dim = 512 \n",
    "    num_layers = 4 \n",
    "\n",
    "    # Build the Transformer model \n",
    "    model = TextGen_TransformerModel(vocab_size, embed_dim, num_heads, ff_dim, num_layers, seq_length)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9aa11-97d1-4f7e-874a-e1377e86e42e",
   "metadata": {},
   "source": [
    "### Q-learning (Reinforcement Learning)\n",
    "- Reinforcement learning algorithm\n",
    "  - **Agents** choose from a set of **Actions**\n",
    "  - **Actions** impact the **Environment**, which impacts **Agents** via **Rewards**\n",
    "  - **Rewards** are unknown and must be estimated by the **Agent**\n",
    "  - The process repeats dynamically, so that **Agents** learn how to estimate **Rewards**\n",
    "- The essence of Q-learning lies in the Q-value function, Q(s, a): yhe Q-values are updated iteratively using the Bellman equation, which incorporates both the immediate reward and the estimated future rewards.\n",
    "- The steps to implement Q-learning with Keras include initializing the environments, building the Q-network, training the Q-network, and evaluating the agent.\n",
    "\n",
    "**Applications**: recommendation engines, marketing, automated bidding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650d2ab-e87b-4c1f-95ae-7097dc41bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym # a toolkit for developing and comparing reinforcement learning algorithms (OpenAI Gym library)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input \n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create the environment \n",
    "# CartPole-v1 is an environment where a pole is balanced on a cart, and the goal is to prevent the pole from falling over \n",
    "# (a common benchmark for reinforcement learning algorithms)\n",
    "env = gym.make('CartPole-v1') \n",
    "\n",
    "# Global settings\n",
    "episodes = 10  # Number of episodes\n",
    "batch_size = 32  # Size of the mini-batch for training\n",
    "epsilon = 1.0  # Starting with a high exploration rate\n",
    "epsilon_min = 0.01  # Minimum exploration rate\n",
    "epsilon_decay = 0.99  # Faster decay rate for epsilon after each episode\n",
    "memory_size=2000\n",
    "\n",
    "memory = deque(maxlen=memory_size)  # Memory buffer to store experiences\n",
    "\n",
    "# Define state size and action size based on the environment\n",
    "state_size = env.observation_space.shape[0]  # State space size from the environment\n",
    "action_size = env.action_space.n  # Number of possible actions from the environment\n",
    "\n",
    "# Define the model building function (takes the state as input and outputs Q-values for each action)\n",
    "def build_model(state_size, action_size): \n",
    "    model = Sequential() \n",
    "    model.add(Input(shape=(state_size,)))  # Use Input layer to specify the input shape \n",
    "    model.add(Dense(24, activation='relu')) \n",
    "    model.add(Dense(24, activation='relu')) \n",
    "    model.add(Dense(action_size, activation='linear')) #linear activation function for the output layer, as we are predicting continuous Q-values\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.001)) \n",
    "    return model \n",
    "\n",
    "model = build_model(state_size, action_size)\n",
    "\n",
    "# Replay memory\n",
    "memory = deque(maxlen=2000)\n",
    "\n",
    "def remember(state, action, reward, next_state, done):\n",
    "    \"\"\"Store experience in memory.\"\"\"\n",
    "    memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "def replay(batch_size):  # Increased batch size\n",
    "    \"\"\"Train the model using a random sample of experiences from memory.\"\"\"\n",
    "    if len(memory) < batch_size:\n",
    "        return  # Skip replay if there's not enough experience\n",
    "\n",
    "    minibatch = random.sample(memory, batch_size)  # Sample a random batch from memory\n",
    "    \n",
    "    # Extract information for batch processing\n",
    "    states = np.vstack([x[0] for x in minibatch])\n",
    "    actions = np.array([x[1] for x in minibatch])\n",
    "    rewards = np.array([x[2] for x in minibatch])\n",
    "    next_states = np.vstack([x[3] for x in minibatch])\n",
    "    dones = np.array([x[4] for x in minibatch])\n",
    "    \n",
    "    # Predict Q-values for the next states in batch\n",
    "    q_next = model.predict(next_states)\n",
    "    # Predict Q-values for the current states in batch\n",
    "    q_target = model.predict(states)\n",
    "    \n",
    "    # Vectorized update of target values\n",
    "    for i in range(batch_size):\n",
    "        target = rewards[i]\n",
    "        if not dones[i]:\n",
    "            target += 0.95 * np.amax(q_next[i])  # Update Q value with the discounted future reward\n",
    "        q_target[i][actions[i]] = target  # Update only the taken action's Q value\n",
    "    \n",
    "    # Train the model with the updated targets in batch\n",
    "    model.fit(states, q_target, epochs=1, verbose=0)  # Train in batch mode\n",
    "\n",
    "    # Reduce exploration rate (epsilon) after each training step\n",
    "    global epsilon\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "def act(state):\n",
    "    \"\"\"Choose an action based on the current state and exploration rate.\"\"\"\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return random.randrange(action_size)  # Explore: choose a random action\n",
    "    act_values = model.predict(state)  # Exploit: predict action based on the state\n",
    "    return np.argmax(act_values[0])  # Return the action with the highest Q-value\n",
    "\n",
    "# Define the number of episodes you want to train the model for\n",
    "episodes = 10  # You can set this to any number you prefer\n",
    "train_frequency = 5  # Train the model every 5 steps\n",
    "\n",
    "for e in range(episodes):\n",
    "    state, _ = env.reset()  # Unpack the tuple returned by env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for time in range(200):  # Limit to 200 time steps per episode\n",
    "        action = act(state)\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        reward = reward if not done else -10\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        remember(state, action, reward, next_state, done)  # Store experience\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            print(f\"episode: {e+1}/{episodes}, score: {time}, e: {epsilon:.2}\")\n",
    "            break\n",
    "        \n",
    "        # Train the model every 'train_frequency' steps\n",
    "        if time % train_frequency == 0:\n",
    "            replay(batch_size)  # Call replay with larger batch size for efficiency\n",
    "\n",
    "env.close()\n",
    "\n",
    "# evaluate the performance of the trained Q-Learning agent\n",
    "for e in range(10):  \n",
    "\n",
    "    state, _ = env.reset()  # Unpack the state from the tuple \n",
    "    state = np.reshape(state, [1, state_size])  # Reshape the state correctly \n",
    "    for time in range(500):  \n",
    "        env.render()  \n",
    "        action = np.argmax(model.predict(state)[0])  \n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)  # Unpack the five return values \n",
    "        done = terminated or truncated  # Check if the episode is done \n",
    "        next_state = np.reshape(next_state, [1, state_size])  \n",
    "        state = next_state  \n",
    "        if done:  \n",
    "            print(f\"episode: {e+1}/10, score: {time}\")  \n",
    "            break  \n",
    "\n",
    "env.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125161e-b135-418b-8273-930700008321",
   "metadata": {},
   "source": [
    "### Autoencoders\n",
    "- Unsupervised learner\n",
    "- A type of neural network used to learn efficient representations of data for the purpose of dimensionality reduction or feature learning\n",
    "- Consist of three main parts:\n",
    "  - Encoder: this part compresses the input into a smaller latent space representation\n",
    "  - Bottleneck: compressed representation\n",
    "  - Decoder: this part reconstructs the input from the latent space representation. \n",
    "- The key idea is that the autoencoder is trained to minimize the difference between the input and the reconstructed output, forcing the network to learn meaningful representations of the data.\n",
    "\n",
    "**Applications:** data denoising, dimensionality reduction, and feature learning\n",
    "\n",
    "**Advanced Autoencoder architectures:** \n",
    "- Variational Autoencoders (VAEs): have probabilistic:  elements used for generating new data samples\n",
    "- Convolutional Autoencoder: use convolutional layers and are effective for image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e00433-060c-4bde-a0d4-66e41b01b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Dense \n",
    "\n",
    "def Autoencoder(input_shape,output_shape):\n",
    "    \n",
    "    input_layer = Input(input_shape)\n",
    "    \n",
    "    # Encoder \n",
    "    encoded = Dense(64, activation='relu')(input_layer) \n",
    "\n",
    "    # Bottleneck \n",
    "    bottleneck = Dense(32, activation='relu')(encoded) \n",
    "\n",
    "    # Decoder \n",
    "    decoded = Dense(64, activation='relu')(bottleneck) \n",
    "    output_layer = Dense(784, activation='sigmoid')(decoded) \n",
    "\n",
    "    # Autoencoder model \n",
    "    model = Model(input_layer, output_layer) \n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d3796-b48e-49d7-9830-177bc01b8993",
   "metadata": {},
   "source": [
    "### Diffusion models\n",
    "\n",
    "- Unsupervised learner\n",
    "- Probabilistic models that generate data by iteratively refining a noisy initial sample\n",
    "- They start with a random noise and gradually apply a series of transformations to produce a coherent data sample\n",
    "- Simulate the physical process of diffusion, where particles spread out from regions of high concentration to regions of low concentration\n",
    "- Diffusion models work by defining a forward process and a reverse process\n",
    "- Consist of three main parts:\n",
    "  - Encoder: this part compresses the input into a smaller latent space representation\n",
    "  - Bottleneck: compressed representation\n",
    "  - Decoder: this part reconstructs the input from the latent space representation. \n",
    "\n",
    "**Applications**: image generation, image enhancement/denoising, data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2c30e-d162-447f-874c-0e2511360d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv2DTranspose, Flatten, Reshape\n",
    "\n",
    "def DiffusionModel(input_shape,output_shape):\n",
    "    \n",
    "    input_layer = Input(shape=(28, 28, 1))\n",
    "    \n",
    "    #Encoder\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)  # Reduced filters\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
    "    \n",
    "    # Bottleneck\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)  # Reduced size\n",
    "    \n",
    "    #Encoder\n",
    "    x = Dense(28*28*32, activation='relu')(x)  # Reduced size\n",
    "    x = Reshape((28, 28, 32))(x)\n",
    "    x = Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
    "    x = Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(x)  # Reduced filters\n",
    "    output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    model = Model(input_layer, output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65c79b-e64c-4020-b5eb-2deab813334a",
   "metadata": {},
   "source": [
    "### Generative Adversarial Networks (GANs)\n",
    "- Unsupervised learner\n",
    "- Consist of two networks:\n",
    "  - Generator network: generates new data instances that resemble the training data.\n",
    "  - Discriminator network: evaluates the authenticity of the generated data.\n",
    "- The two networks are trained simultaneously through adversarial training: the generator tries to fool the discriminator while the discriminator tries to distinguish between real and fake data. This adversarial process leads to the generator producing increasingly realistic data. \n",
    "\n",
    "**Applications:** image generation, text-to-image synthesis, image-to-image translation, data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc3d74-f87a-47e5-a3cb-a81e88dd5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten\n",
    "\n",
    "# Define the generator model\n",
    "# The generator takes a random noise vector as an input and generates a synthetic image\n",
    "def build_generator(): \n",
    "    model = Sequential() \n",
    "    model.add(Dense(256, input_dim=100)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(512)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(1024)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(Dense(28 * 28 * 1, activation='tanh')) \n",
    "    model.add(Reshape((28, 28, 1))) \n",
    "    return model \n",
    "\n",
    "# Build the generator \n",
    "generator = build_generator() \n",
    "generator.summary()\n",
    "\n",
    "# Define the discriminator model\n",
    "# The discriminator takes an image as an input and outputs a probability indicating whether the image is real or fake\n",
    "def build_discriminator(): \n",
    "    model = Sequential() \n",
    "    model.add(Flatten(input_shape=(28, 28, 1))) \n",
    "    model.add(Dense(512)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(Dense(256)) \n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "    return model \n",
    "\n",
    "# Build and compile the discriminator \n",
    "discriminator = build_discriminator() \n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "discriminator.summary()\n",
    "\n",
    "# Create the GAN by stacking the generator and the discriminator\n",
    "# The GAN takes a noise vector as an input, generates a synthetic image using the generator, and classifies the image using the discriminator\n",
    "def build_gan(generator, discriminator): \n",
    "    discriminator.trainable = False # The discriminator is set to non-trainable when compiling the GAN to ensure that only the generator is updated during the adversarial training. \n",
    "    gan_input = Input(shape=(100,)) # Create an input layer for the noise vector\n",
    "    generated_image = generator(gan_input) # Pass the noise vector through the generator to produce a synthetic image. \n",
    "    gan_output = discriminator(generated_image) #Pass the synthetic image through the discriminator to get the classification.\n",
    "    model = Model(gan_input, gan_output) # Compile the GAN using binary cross-entropy loss and the Adam optimizer.\n",
    "\n",
    "    return model \n",
    "\n",
    "# Build the GAN \n",
    "gan = build_gan(generator, discriminator) \n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6ef90-26d6-42d6-9b1d-b76deeafe4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters \n",
    "batch_size = 64 \n",
    "epochs = 50\n",
    "sample_interval = 10\n",
    "\n",
    "# Adversarial ground truths \n",
    "real = np.ones((batch_size, 1)) \n",
    "fake = np.zeros((batch_size, 1)) \n",
    "\n",
    "# Training loop \n",
    "for epoch in range(epochs): \n",
    "    # Train the discriminator \n",
    "    idx = np.random.randint(0, x_train.shape[0], batch_size) \n",
    "    real_images = x_train[idx] \n",
    "    noise = np.random.normal(0, 1, (batch_size, 100)) \n",
    "    generated_images = generator.predict(noise) \n",
    "    d_loss_real = discriminator.train_on_batch(real_images, real) \n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, fake) \n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
    "\n",
    "    # Train the generator \n",
    "    noise = np.random.normal(0, 1, (batch_size, 100)) \n",
    "    g_loss = gan.train_on_batch(noise, real) \n",
    "\n",
    "    # Print the progress \n",
    "    if epoch % sample_interval == 0: \n",
    "        print(f\"{epoch} [D loss: {d_loss[0]}] [D accuracy: {100 * d_loss[1]}%] [G loss: {g_loss}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27f85f-6433-4c4d-a141-e0b72ec0d9b3",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d42823-422f-4376-8dad-4618ba979494",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d0e9a-4b20-4092-a39c-01f5d1acd2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Custom augmentation function\n",
    "def add_random_noise(image):\n",
    "    noise = np.random.normal(0, 0.1, image.shape)\n",
    "    return image + noise\n",
    "\n",
    "# Create an instance of ImageDataGenerator with basic augmentations\n",
    "datagen = ImageDataGenerator(\n",
    "    \n",
    "    #basic augmentations\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    \n",
    "    #normalizations\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    samplewise_center=True,\n",
    "    samplewise_std_normalization=True,\n",
    "    \n",
    "    #custom augmentations\n",
    "    preprocessing_function=add_random_noise\n",
    ")\n",
    "\n",
    "#Only required if featurewise_center or featurewise_std_normalization or zca_whitening are set to True\n",
    "# datagen.fit(train_data) #Computes the internal data stats related to the data-dependent transformations\n",
    "\n",
    "# Visualizing multiple augmented versions of the same image\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i, batch in enumerate(datagen.flow(x, batch_size=1)):\n",
    "#     if i >= 4:  # Show only 4 versions\n",
    "#         break\n",
    "#     plt.subplot(2, 2, i+1)\n",
    "#     plt.imshow(batch[0].astype('uint8'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239b3209-ad17-4e86-87cc-c08802aa5de2",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5002081-df3f-4f55-9bc7-28facded83af",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff648e-3cf7-49a8-8d5d-03f44b5d769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "# input_shape = X_train.shape[1:]\n",
    "# output_shape = y_train.shape[1] # number of categories\n",
    "# model = simple_CNN(input_shape, output_shape)\n",
    "\n",
    "model = TextGen_Transformer()\n",
    "\n",
    "model.summary()\n",
    "# plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0018c-316c-4d7e-ad8d-94afd43e48fa",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f148f1-bbd2-4d35-a5cd-8bb82181b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer options\n",
    "optimizer='adam'\n",
    "\n",
    "#Loss options\n",
    "loss='mean_squared_error' # Regression\n",
    "loss='categorical_crossentropy' # Multi-classification\n",
    "loss='binary_crossentropy' # Binary classification\n",
    "\n",
    "#Metrics options\n",
    "metrics=['accuracy']\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer, loss, metrics) # Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b69acc-9cd8-4934-bb13-485e627e87c1",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75124d45-0034-46f6-9b7e-98c0aec36369",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.3, epochs=n_epochs, verbose=2) #with validation set, but training data not split into training and validation\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=n_epochs, verbose=2) #with validation set, training data has already been split\n",
    "model.fit(train_generator, validation_data=valid_generator, epochs = n_epochs, verbose=2) #when using data generators\n",
    "model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size) #without validation set\n",
    "model.fit(X_train_noisy, X_train, epochs=n_epochs, batch_size=batch_size, shuffle=True, validation_data=(X_test, X_test)) #autoencoders, diffusion model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d04675-07a9-4cf3-9e5c-3011bcc17705",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d125d7-694a-4159-9585-fff4b83725f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores = model.evaluate(test_generator, verbose=0)\n",
    "print(\"Loss: {} \\n Accuracy: {} \\n Error: {}\".format(scores[0], scores[1], 100-scores[1]*100))\n",
    "\n",
    "#Visualise training results (plot the loss and accuracy curves)\n",
    "train_history = model.history.history  # After training\n",
    "\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(train_history['loss'])\n",
    "plt.plot(train_history['val_loss'])\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Accuracy Curves\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.plot(train_history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(train_history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813faf5d-d160-41ae-99ca-cce8e26f37af",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c243e-9f98-4a03-8ed4-3186c16a1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model-building function \n",
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a RandomSearch Tuner \n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='intro_to_kt'\n",
    ")\n",
    "\n",
    "# Display a summary of the search space \n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Run the hyperparameter search \n",
    "tuner.search(X_train, y_train, epochs=5, validation_data=(x_val, y_val)) \n",
    "\n",
    "# Display a summary of the results \n",
    "tuner.results_summary() \n",
    "\n",
    "# Retrieve the best hyperparameters \n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0] \n",
    "print(f\"\"\" \n",
    "\n",
    "The optimal number of units in the first dense layer is {best_hps.get('units')}. \n",
    "\n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}. \n",
    "\n",
    "\"\"\") \n",
    "\n",
    "#Build and Train the Model with Best Hyperparameters \n",
    "model = tuner.hypermodel.build(best_hps) \n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.2) \n",
    "\n",
    "# Evaluate the model on the test set \n",
    "test_loss, test_acc = model.evaluate(X_val, y_val) \n",
    "print(f'Test accuracy: {test_acc}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db54914c-8916-4cb0-9dab-3c6c8571a675",
   "metadata": {},
   "source": [
    "### Learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657adb9-b54c-47a2-b695-a890d1b35cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "import tensorflow as tf\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))\n",
    "    \n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae8ebbd-482a-4045-be4e-de9e3b58132a",
   "metadata": {},
   "source": [
    "### Custom training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f56014-2566-4116-ae53-bbb5d364f45b",
   "metadata": {},
   "source": [
    "Can be implemented instead of using the standard Keras fit method for a more tailored training process.\n",
    "\n",
    "**Advantages**:\n",
    "- Custom loss functions and optimization strategies.\n",
    "- Enable advanced logging and monitoring\n",
    "- Flexibility for research\n",
    "- Integration with custom operations and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def6ab9-519e-4a51-b8e0-5f7901985df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
    "optimizer = keras.optimizers.Adam()\n",
    "accuracy_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "epochs = 5  # Number of epochs for training\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            # Compute loss\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        \n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # Apply gradients to update model weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Update the accuracy metric\n",
    "        accuracy_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log the loss and accuracy every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()} Accuracy = {accuracy_metric.result().numpy()}')\n",
    "    \n",
    "    # Reset the metric at the end of each epoch\n",
    "    accuracy_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e1e33-e633-429f-8728-446cd6a5b7ec",
   "metadata": {},
   "source": [
    "### Custom callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cb24f-8fef-49ff-a656-bf6d706ed7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback \n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Loss function for multi-class classification\n",
    "optimizer = keras.optimizers.Adam()  # Adam optimizer for efficient training\n",
    "accuracy_metric = keras.metrics.SparseCategoricalAccuracy()  # Metric to track accuracy during training\n",
    "\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        print(f'End of epoch {epoch + 1}, loss: {logs.get(\"loss\")}, accuracy: {logs.get(\"accuracy\")}')\n",
    "        \n",
    "model.fit(X_train, y_train, epochs=10, callbacks=[CustomCallback()]) #with validation set, but training data not split into training and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feae166a-481a-4d62-b942-898b740c6158",
   "metadata": {},
   "source": [
    "## Other Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44935403-2ac5-4c95-a423-d147059398ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save and load Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4c9bf-5933-4a5f-b032-2fe9f3a26ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('filename.h5')\n",
    "pretrained_model = keras.models.load_model('filename.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba03331-31cd-4f42-8936-00a1916e5b60",
   "metadata": {},
   "source": [
    "### Mixed precision training\n",
    "Mixed precision training involves using both 16-bit and 32-bit floating-point types to speed up training on modern GPUs, leading to faster computation and reduced memory usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbf66d-64cc-4883-8461-94aa5e1dd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e4209-3b65-4f6b-90e4-a1e679cd2a39",
   "metadata": {},
   "source": [
    "### Model pruning\n",
    "Model pruning reduces the number of parameters in a model by removing less significant connections or neurons, making it more efficient without a substantial loss in accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47297017-a0b7-47fd-a3a1-4a317cb0a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install tensorflow-model-optimization\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude =tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Apply pruning to model\n",
    "pruning_params = {'prunint_schedule':\n",
    "                  tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0,\n",
    "                                                       final_sparsity=0.5,\n",
    "                                                       begin_step=0,\n",
    "                                                       end_step=2000)}\n",
    "\n",
    "model_pruned=prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc8c70-bd30-4e56-8278-529608477c5e",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "Reduces the precision of the numbers used to represent the models' weights, which helps in deploying models on edge devices by reducing memory usage and inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d34b01-7dfd-41cb-b2cb-7b53159ac65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_model = converter.convert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-lab-kernel",
   "language": "python",
   "name": "jupyter-lab-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
